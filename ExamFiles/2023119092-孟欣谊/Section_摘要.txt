摘要 针对自动驾驶在复杂场景中的决策优化难题，本研究提出了一种基于分层注意力机制的深度强化学习（HA-DDPG）算法。通过构建双线性交互注意力模块，算法实现了多模态交通状态的高效表征与动态权重分配，显著提升了系统在长尾场景中的决策可靠性。实验基于上海市200小时真实驾驶数据，采用PyTorch框架验证表明：相较于传统DDPG方法，HA-DDPG将复杂路口场景的决策成功率提升至98.7%（提升31%），延迟降低42%至50ms，同时乘坐舒适度改善25%。研究进一步设计了课程学习策略和安全验证模块，解决了DRL训练收敛慢与可解释性差的双重瓶颈。该成果为L4级自动驾驶提供了可落地的决策方案，目前已在北京高级别示范区完成技术验证，并符合《自动驾驶伦理指南》对决策透明性的要求。
关键词 深度强化学习；自动驾驶决策；分层注意力机制；多模态感知；长尾场景优化；实时性控制；驾驶策略可解释性
Research on Optimization of Autonomous Vehicle Decision-Making Systems Based on Deep Reinforcement Learning
xinyi,Meng
Department of School of Stomatology, University, City Guangzhou, China
Abstract
This study presents a breakthrough in autonomous vehicle decision-making systems through the development of a Hierarchical Attention-based Deep Deterministic Policy Gradient (HA-DDPG) algorithm, specifically designed to address critical challenges in complex urban driving scenarios. The research focuses on three fundamental limitations of current autonomous decision systems: inadequate reliability in long-tail scenarios, suboptimal multi-objective optimization, and poor interpretability that hinders regulatory approval.
At its core, the HA-DDPG algorithm introduces an innovative bilinear interactive attention module that revolutionizes how autonomous systems process multimodal traffic data. This module enables dynamic weight allocation across different sensory inputs and traffic states, allowing for more nuanced understanding of complex driving environments. The hierarchical architecture consists of four integrated components: 1) an environmental perception layer for multi-sensor data fusion, 2) a feature extraction layer employing Transformer-based spatiotemporal encoding, 3) the novel attention-enhanced decision layer, and 4) an execution layer for vehicle control command generation.
The experimental validation framework incorporated 200 hours of real-world driving data collected from Shanghai's mixed traffic environments, containing over 50 typical road scenarios and 1,200 interactive decision processes. Implemented using Python 3.9 and PyTorch 1.12 with Stable-Baselines3 reinforcement learning libraries, the system demonstrated remarkable performance improvements. Key quantitative results include: a 98.7% decision success rate at complex intersections (31% improvement over baseline DDPG), latency reduction to 50ms (42% faster processing), and 25% enhancement in ride comfort as measured by Jerk metrics. Statistical significance was confirmed through 5-fold cross-validation (p=0.0032).
Beyond the core algorithm, two auxiliary innovations significantly contribute to the system's practical viability. First, a curriculum learning strategy was developed to accelerate training convergence, addressing the notoriously slow training processes of conventional DRL approaches. Second, a safety verification module was implemented to enhance decision interpretability, creating transparent logs of attention weight distributions across different traffic elements during decision events.
The research outcomes have progressed beyond theoretical development to practical validation. The system has completed successful technical demonstrations at Beijing's Advanced Autonomous Driving Demonstration Zone, showing particular effectiveness in handling China-specific traffic challenges like mixed flows of vehicles, bicycles, and pedestrians. From an industry adoption perspective, the technology is currently being adapted for commercial deployment in logistics applications within one year, with planned expansion to urban RoboTaxi services within 3-5 years.
Notably, this work incorporates important ethical considerations by design. The safety verification module provides decision traceability that aligns with China's "Autonomous Driving Ethics Guidelines", particularly regarding protection of vulnerable road users. The attention weight visualization also offers regulators tangible evidence of how decisions are made, addressing the "black box" concerns prevalent in AI-driven autonomous systems.
This research makes three primary contributions to the field: 1) a novel hierarchical attention mechanism that advances state representation in DRL, 2) a comprehensive framework balancing decision accuracy, speed and comfort, and 3) practical solutions for real-world deployment challenges including training efficiency and regulatory compliance. The HA-DDPG architecture establishes a new benchmark for autonomous decision systems in complex urban environments while providing a template for responsible AI development in safety-critical applications.
Key words
Deep Reinforcement Learning；Autonomous Vehicle Decision-Making；Hierarchical Attention Mechanism；Multimodal Perception；Long-Tail Scenario Optimization；Real-Time Control；Interpretability of Driving Policies