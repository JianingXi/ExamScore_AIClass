摘要：本研究针对多模态医学影像诊断中的核心挑战，提出了一种基于Transformer的动态门控跨模态对比学习框架（DG-CCL），旨在解决模态对齐、特征融合和动态适应性三大技术瓶颈。通过设计跨模态对比损失函数和动态门控权重生成网络，实现了CT与PET影像的高阶语义融合，显著提升了诊断精度与鲁棒性。实验结果表明，在自主构建的多模态肺结节诊断数据集（MLNDD）上，本方法的AUC达到0.916，较传统晚期融合方法提升3.1%，且模态缺失场景下的性能下降幅度仅为0.04。此外，动态门控机制使恶性病例中PET模态的权重占比显著高于良性病例（68% vs 43%），体现了病灶特性的自适应分析能力。本研究不仅为医学影像的多模态融合提供了创新理论框架，还具有显著的临床应用价值，预计可缩短单例诊断耗时58%，并为脑肿瘤、心血管疾病等扩展场景提供技术支撑。最后，研究探讨了算法偏见、隐私保护等伦理问题，提出了标准化治理路径，为人工智能在精准医疗中的可持续发展提供了重要参考。
关键词：多模态医学影，Transformer模型，动态门控融合，对比学习，肺结节诊断，特征空间对齐