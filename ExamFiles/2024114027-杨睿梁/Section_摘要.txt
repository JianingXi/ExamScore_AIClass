摘要：跨模态Transformer技术为解决多模态医学数据融合中的非对齐性和异构性问题提供了创新解决方案。本研究系统分析了该技术在医学人工智能领域的应用现状与发展趋势。在CMU-MOSEI医疗情感分析任务中，基于跨模态注意力机制的方法比传统LSTM模型在F1分数上提升15%；在FFA-IR眼科报告生成任务中，CIDEr指标从0.561提高到0.599；在IEMOCAP数据集上的AUC达到0.78。通过引入方向性跨模态注意力机制，模型能够在不依赖数据预对齐的情况下建立模态间关联，在50例非对齐多模态临床数据测试中，人工评估准确率提升44.7%。研究证实，跨模态Transformer通过低阶特征自适应融合和长程依赖建模，有效解决了医学多模态数据分析中的关键挑战，为智慧医疗系统提供了新的技术路径。
关键词：跨模态Transformer；多模态医学数据；非对齐序列；注意力机制；医学人工智能
A Cross-modal Transformer Approach for Multimodal Medical Data Fusion
Young
Abstract：Cross-modal Transformer technology provides innovative solutions to address the challenges of unaligned and heterogeneous multimodal medical data fusion. This study systematically analyzes the current applications and development trends of this technology in the field of medical artificial intelligence. In the CMU-MOSEI medical sentiment analysis task, the cross-modal attention-based method improves the F1 score by 15% compared to traditional LSTM models; in the FFA-IR ophthalmic report generation task, the CIDEr metric increases from 0.561 to 0.599; and achieves an AUC of 0.78 on the IEMOCAP dataset. By introducing directional cross-modal attention mechanisms, the model establishes inter-modal correlations without relying on data pre-alignment, demonstrating a 44.7% improvement in manual evaluation accuracy on a test set of 50 unaligned multimodal clinical cases. The research confirms that cross-modal Transformer effectively addresses key challenges in multimodal medical data analysis through low-level feature adaptive fusion and long-range dependency modeling, providing a new technical approach for smart healthcare systems.
Keywords: cross-modal Transformer; multimodal medical data; unaligned sequences; attention mechanism; medical AI